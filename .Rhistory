tstrain = ts(training$visitsTumblr)
testing = dat[year(dat$date)>2011,]
test = dat[year(dat$date) > 2011,]
pred <- forecast(fit, h=length(test$visitsTumblr),level=c(80,95))
fcast <- forecast(fit)
plot(fcast)
accuracy(fcast,test$visitsTumblr)
modBats <- bats(tstrain)
pred <- forecast(modBats, h=length(testing$visitsTumblr),level=c(80,95))
accuracy <- 1-sum(testing$visitsTumblr>pred$upper[,2])/length(testing$visitsTumblr)
accuracy <- 1-sum(test$visitsTumblr>pred$upper[,2])/length(test$visitsTumblr)
library(lubridate)
library(forecast)
dat = read.csv("./gaData.csv")
training = dat[year(dat$date)==2011,]
tstrain = ts(training$visitsTumblr)
testing = dat[year(dat$date)>2011,]
test = dat[year(dat$date) > 2011,]
pred <- forecast(fit, h=length(test$visitsTumblr),level=c(80,95))
fcast <- forecast(fit)
plot(fcast)
accuracy(fcast,test$visitsTumblr)
modBats <- bats(tstrain)
pred <- forecast(modBats, h=length(testing$visitsTumblr),level=c(80,95))
accuracy <- 1-sum(testing$visitsTumblr>pred$upper[,2])/length(testing$visitsTumblr)
accuracy <- 1-sum(test$visitsTumblr>pred$upper[,2])/length(test$visitsTumblr)
1
1
1
library(lubridate)
library(forecast)
dat = read.csv("./gaData.csv")
training = dat[year(dat$date)==2011,]
tstrain = ts(training$visitsTumblr)
testing = dat[year(dat$date)>2011,]
test = dat[year(dat$date) > 2011,]
pred <- forecast(fit, h=length(test$visitsTumblr),level=c(80,95))
fcast <- forecast(fit)
plot(fcast)
accuracy(fcast,test$visitsTumblr)
modBats <- bats(tstrain)
pred <- forecast(modBats, h=length(testing$visitsTumblr),level=c(80,95))
accuracy <- 1-sum(testing$visitsTumblr>pred$upper[,2])/length(testing$visitsTumblr)
accuracy <- 1-sum(test$visitsTumblr>pred$upper[,2])/length(test$visitsTumblr)
library(lubridate)
library(forecast)
dat = read.csv("./08 Machine Learning/gaData.csv")
training = dat[year(dat$date)==2011,]
tstrain = ts(training$visitsTumblr)
testing = dat[year(dat$date)>2011,]
test = dat[year(dat$date) > 2011,]
pred <- forecast(fit, h=length(test$visitsTumblr),level=c(80,95))
fcast <- forecast(fit)
plot(fcast)
accuracy(fcast,test$visitsTumblr)
modBats <- bats(tstrain)
pred <- forecast(modBats, h=length(testing$visitsTumblr),level=c(80,95))
accuracy <- 1-sum(testing$visitsTumblr>pred$upper[,2])/length(testing$visitsTumblr)
accuracy <- 1-sum(test$visitsTumblr>pred$upper[,2])/length(test$visitsTumblr)
library(lubridate)
library(forecast)
dat = read.csv("./08 Machine Learning/gaData.csv")
training = dat[year(dat$date)==2011,]
tstrain = ts(training$visitsTumblr)
testing = dat[year(dat$date)>2011,]
test = dat[year(dat$date) > 2011,]
pred <- forecast(fit, h=length(test$visitsTumblr),level=c(80,95))
fcast <- forecast(fit)
plot(fcast)
accuracy(fcast,test$visitsTumblr)
modBats <- bats(tstrain)
pred <- forecast(modBats, h=length(testing$visitsTumblr),level=c(80,95))
accuracy <- 1-sum(testing$visitsTumblr>pred$upper[,2])/length(testing$visitsTumblr)
accuracy <- 1-sum(test$visitsTumblr>pred$upper[,2])/length(test$visitsTumblr)
library(lubridate)
library(forecast)
dat = read.csv("./08 Machine Learning/gaData.csv")
training = dat[year(dat$date)==2011,]
tstrain = ts(training$visitsTumblr)
testing = dat[year(dat$date)>2011,]
test = dat[year(dat$date) > 2011,]
pred <- forecast(fit, h=length(test$visitsTumblr),level=c(80,95))
fcast <- forecast(fit)
plot(fcast)
accuracy(fcast,test$visitsTumblr)
modBats <- bats(tstrain)
pred <- forecast(modBats, h=length(testing$visitsTumblr),level=c(80,95))
accuracy <- 1-sum(testing$visitsTumblr>pred$upper[,2])/length(testing$visitsTumblr)
accuracy <- 1-sum(test$visitsTumblr>pred$upper[,2])/length(test$visitsTumblr)
library(lubridate) # For year() function below
dat = read.csv("./08 Machine Learning//gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(lubridate) # For year() function below
dat = read.csv("./08 Machine Learning//gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
library(lubridate) # For year() function below
dat = read.csv("./08 Machine Learning//gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
library(quantmod)
library(lubridate) # For year() function below
dat = read.csv("./08 Machine Learning//gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
library(quantmod)
library(lubridate) # For year() function below
dat = read.csv("./08 Machine Learning//gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
library(quantmod)
fit <- bats(tstrain)
rm(list=ls())
library(lubridate) # For year() function below
dat = read.csv("./08 Machine Learning//gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
library(quantmod)
fit <- bats(tstrain)
dim(testing)[1]
dim(testing)
#rm(list=ls())
library(lubridate) # For year() function below
dat = read.csv("./08 Machine Learning//gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
library(quantmod)
fit <- bats(tstrain)
h <- dim(testing)[1]
fcast <- forecast(fit, level = 95, h = h)
#rm(list=ls())
library(lubridate) # For year() function below
dat = read.csv("./08 Machine Learning//gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
library(quantmod)
fit <- bats(tstrain)
h <- dim(testing)[1]
fcast <- forecast(fit, level = 95, h = h)
accuracy(fcast, testing$visitsTumblr)
c()
#rm(list=ls())
library(lubridate) # For year() function below
dat = read.csv("./08 Machine Learning//gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
library(quantmod)
fit <- bats(tstrain)
h <- dim(testing)[1]
fcast <- forecast(fit, level = 95, h = h)
accuracy(fcast, testing$visitsTumblr)
result <- c()
l <- length(fcast$lower)
for (i in 1:l) {
x <- testing$visitsTumblr[i]
a <- fcast$lower[i] < x & x < fcast$upper[i]
result <- c(result, a)
}
#rm(list=ls())
library(lubridate) # For year() function below
dat = read.csv("./08 Machine Learning//gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
library(quantmod)
fit <- bats(tstrain)
h <- dim(testing)[1]
fcast <- forecast(fit, level = 95, h = h)
accuracy(fcast, testing$visitsTumblr)
result <- c()
l <- length(fcast$lower)
for (i in 1:l) {
x <- testing$visitsTumblr[i]
a <- fcast$lower[i] < x & x < fcast$upper[i]
result <- c(result, a)
}
sum(result)/l * 100
library(lubridate)
library(forecast)
dat = read.csv("./08 Machine Learning/gaData.csv")
training = dat[year(dat$date)==2011,]
tstrain = ts(training$visitsTumblr)
testing = dat[year(dat$date)>2011,]
test = dat[year(dat$date) > 2011,]
pred <- forecast(fit, h=length(test$visitsTumblr),level=c(80,95))
fcast <- forecast(fit)
plot(fcast)
accuracy(fcast,test$visitsTumblr)
modBats <- bats(tstrain)
pred <- forecast(modBats, h=length(testing$visitsTumblr),level=c(80,95))
accuracy <- 1-sum(testing$visitsTumblr>pred$upper[,2])/length(testing$visitsTumblr)
accuracy <- 1-sum(test$visitsTumblr>pred$upper[,2])/length(test$visitsTumblr)
library(lubridate)
library(forecast)
dat = read.csv("./08 Machine Learning/gaData.csv")
training = dat[year(dat$date)==2011,]
tstrain = ts(training$visitsTumblr)
testing = dat[year(dat$date)>2011,]
test = dat[year(dat$date) > 2011,]
pred <- forecast(fit, h=length(test$visitsTumblr),level=c(80,95))
fcast <- forecast(fit)
plot(fcast)
accuracy(fcast,test$visitsTumblr)
modBats <- bats(tstrain)
pred <- forecast(modBats, h=length(testing$visitsTumblr),level=c(80,95))
accuracy1 <- 1-sum(testing$visitsTumblr>pred$upper[,2])/length(testing$visitsTumblr)
accuracy2 <- 1-sum(test$visitsTumblr>pred$upper[,2])/length(test$visitsTumblr)
accuracy1
accuracy2
#rm(list=ls())
library(lubridate) # For year() function below
dat = read.csv("./08 Machine Learning//gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
library(quantmod)
fit <- bats(tstrain)
h <- dim(testing)[1]
fcast <- forecast(fit, level = 95, h = h)
accuracy(fcast, testing$visitsTumblr)
result <- c()
l <- length(fcast$lower)
for (i in 1:l) {
x <- testing$visitsTumblr[i]
a <- fcast$lower[i] < x & x < fcast$upper[i]
result <- c(result, a)
}
sum(result)/l * 100
library(e1071)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
svmFit <- svm(CompressiveStrength ~ ., data = training)
svmPred <- predict(svmFit,testing)
accuracy(svmPred, testing$CompressiveStrength)
library(e1071)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
svmFit <- svm(CompressiveStrength ~ ., data = training)
svmPred <- predict(svmFit,testing)
accuracy(svmPred, testing$CompressiveStrength)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
rm(list=ls())
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
#rm(list=ls())
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(caret)
library(e1071)
#rm(list=ls())
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(caret)
library(e1071)
fit <- train(CompressiveStrength ~ ., data = training, method = "svmRadial")
prediction <- predict(fit, testing)
accuracy(prediction, testing$CompressiveStrength)
library(e1071)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
svmFit <- svm(CompressiveStrength ~ ., data = training)
svmPred <- predict(svmFit,testing)
accuracy(svmPred, testing$CompressiveStrength)
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot, s = slider(0, 2, step = 0.1))
myplot()
myPlot()
manipulate(myPlot, s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), slider = x(0, 2, step = 0.1))
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
?mean
?lm
?dgamma
?colSums
mean(3)
mean
lm
?colSums
?dgamma
?lm
?mean
library(help=ColSums)
library(help=stats)
library(help=base)
?getMethod
?getClass
?showMethods
?
getS3method()
?showMethods()
showMethods(colSums)
showMethods(dgamma)
showMethods(lm)
showMethods(mean)
createmean <- function(x) {
answer <- mean(x)
return(answer)
}
creatmean(9)
createmean(9)
createmean(2014-03-04)
createmean("2014-03-04")
createmean(TRUE)
createmean(cbind(TRUE) )
createmean(cbind(TRUE, FALSE) )
?createmean
??createmean
?createmean
This function calculates the mean
@param x is a numeric vector
@return the mean of x
@export
@examples
x <- 1:10
createmean(x)
createmean <- function(x) {
answer <- mean(x)
return(answer)
}
?createmean
#' This function calculates the mean
#'
#' @param x is a numeric vector
#' @export
#' @examples
#' x <- 1:10
#' createmean(x)
createmean <- function(x) {
answer <- mean(x)
return(answer)
}
?createmean
runApp()
getwd()
setwd("C:/Users/roger_000/Brooklyn-Cloud/Education/Data Science/WD/09 Developing Data Products")
runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp('C:/Users/roger_000/Brooklyn-Cloud/Education/Data Science/GitHub/courses/09_DevelopingDataProducts/shiny/testApp')
shiny::runApp('C:/Users/roger_000/Brooklyn-Cloud/Education/Data Science/GitHub/courses/09_DevelopingDataProducts/shiny/simplestApp')
shiny::runApp('C:/Users/roger_000/Brooklyn-Cloud/Education/Data Science/GitHub/courses/09_DevelopingDataProducts/shiny/markupApp')
shiny::runApp('C:/Users/roger_000/Brooklyn-Cloud/Education/Data Science/GitHub/courses/09_DevelopingDataProducts/shiny/inputApp')
shiny::runApp('C:/Users/roger_000/Brooklyn-Cloud/Education/Data Science/GitHub/courses/09_DevelopingDataProducts/shiny/graphApp')
shiny::runApp('C:/Users/roger_000/Brooklyn-Cloud/Education/Data Science/GitHub/courses/09_DevelopingDataProducts/shiny2/testApp')
shiny::runApp('C:/Users/roger_000/Brooklyn-Cloud/Education/Data Science/GitHub/courses/09_DevelopingDataProducts/shiny2/testApp2')
shiny::runApp('C:/Users/roger_000/Brooklyn-Cloud/Education/Data Science/GitHub/courses/09_DevelopingDataProducts/shiny2/testApp3')
install.packages("googleVis")
install.packages("googleVis")
install.packages("googleVis")
install.packages("googleVis")
library("googleVis")
install.packages("rgl")
My test presentation
library(yhatr)
install.packages("yhatr")
library(stats)
library(graphics)
cars
load(cars)
data(cars)
lm(dist ~ dist, cars)
shiny::runApp('C:/Users/roger_000/Brooklyn-Cloud/Education/Data Science/GitHub/courses/09_DevelopingDataProducts/shiny/graphApp')
shiny::runApp('C:/Users/roger_000/Brooklyn-Cloud/Education/Data Science/GitHub/courses/09_DevelopingDataProducts/shiny/inputApp')
shiny::runApp('C:/Users/roger_000/Brooklyn-Cloud/Education/Data Science/GitHub/courses/09_DevelopingDataProducts/shiny/markupApp')
shiny::runApp()
shiny::runApp('C:/Users/roger_000/Brooklyn-Cloud/Education/Data Science/GitHub/courses/09_DevelopingDataProducts/shiny/testApp')
lm(dist ~ dist, cars)
cars
names(cars)
?cars
shiny::runApp()
shiny::runApp()
require(stats); require(graphics)
plot(cars, xlab = "Speed (mph)", ylab = "Stopping distance (ft)",
las = 1)
lines(lowess(cars$speed, cars$dist, f = 2/3, iter = 3), col = "red")
title(main = "cars data")
plot(cars, xlab = "Speed (mph)", ylab = "Stopping distance (ft)",
las = 1, log = "xy")
title(main = "cars data (logarithmic scales)")
lines(lowess(cars$speed, cars$dist, f = 2/3, iter = 3), col = "red")
summary(fm1 <- lm(log(dist) ~ log(speed), data = cars))
opar <- par(mfrow = c(2, 2), oma = c(0, 0, 1.1, 0),
mar = c(4.1, 4.1, 2.1, 1.1))
plot(fm1)
par(opar)
lm(log(dist) ~ log(speed), data = cars)
plot(lm(log(dist) ~ log(speed), data = cars))
shiny::runApp()
shiny::runApp()
?predict
x <- rnorm(15)
y <- x + rnorm(15)
predict(lm(y ~ x))
new <- data.frame(x = seq(-3, 3, 0.5))
predict(lm(y ~ x), new, se.fit = TRUE)
pred.w.plim <- predict(lm(y ~ x), new, interval = "prediction")
pred.w.clim <- predict(lm(y ~ x), new, interval = "confidence")
matplot(new$x, cbind(pred.w.clim, pred.w.plim[,-1]),
lty = c(1,2,2,3,3), type = "l", ylab = "predicted y")
pred.w.plim
shiny::runApp()
shiny::runApp()
shiny::runApp()
fit <- lm(dist ~ speed, data = cars)
new.speed <- data.frame(10)
new.speed
predict(fit, newdata = new.speed)
predict(fit, newdata = data.frame(10))
predict(f)
predict(fit)
plot(fit)
plot(cars)
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp('asdf')
shiny::runApp('asdf')
shiny::runApp('asdf')
shiny::runApp('asdf')
shiny::runApp('asdf')
shiny::runApp('asdf')
```
(test-figure/unnamed-chunk-2.png)
```
install_github('slidify', 'ramnathv')
install.packages("devtools")
library(devtools)
install_github('slidify', 'ramnathv')
install_github('slidifyLibraries', 'ramnathv')
library(slidify)
getwd()
slidify("index.Rmd")
library(slidify)
slidify("index.Rmd")
getwd()
setwd("C:/Users/roger_000/Brooklyn-Cloud/Education/Data Science/WD/09 Developing Data Products/first_deck")
publish(title = 'mytitle', 'index.html', host = 'rpubs')
setwd("C:/Users/roger_000/Brooklyn-Cloud/Education/Data Science/WD/09 Developing Data Products/Slidify")
author("first_deck")
setwd("C:/Users/roger_000/Brooklyn-Cloud/Education/Data Science/WD/09 Developing Data Products/Slidify")
author("stopping_distance")
setwd("C:/Users/roger_000/Brooklyn-Cloud/Education/Data Science/WD/09 Developing Data Products/Slidify")
author("stopping_distance")
setwd("C:/Users/roger_000/Brooklyn-Cloud/Education/Data Science/WD/09 Developing Data Products/asdf/Slidify")
author("stopping_distance")
setwd("C:/Users/roger_000/Brooklyn-Cloud/Education/Data Science/WD/09 Developing Data Products/asdf/slidify")
publish(title = 'stopping_distance', 'index.html', host = 'rpubs')
setwd("C:/Users/roger_000/Brooklyn-Cloud/Education/Data Science/WD/09 Developing Data Products/asdf/slidify/stopping_distance")
publish(title = 'stopping_distance', 'index.html', host = 'rpubs')
